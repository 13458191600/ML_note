{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8432a681",
   "metadata": {},
   "source": [
    "## Chapter2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c1d5a0",
   "metadata": {},
   "source": [
    "### error rate\n",
    "\n",
    "- training error\n",
    "\n",
    "- generalization error\n",
    "\n",
    "### fitting\n",
    "\n",
    "- training error is low but generalization error  is high\n",
    "\n",
    "  - overfitting\n",
    "\n",
    "    - gets one-to-one function\n",
    "\n",
    "    - can’t be avoided\n",
    "\n",
    "      - P != NP\n",
    "\n",
    "- training error is high\n",
    "\n",
    "  - underfitting\n",
    "\n",
    "- generalization error  is low\n",
    "\n",
    "  - nice model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff6510",
   "metadata": {},
   "source": [
    "### model selection \n",
    "\n",
    "- divide dataset into training and test space\n",
    "\n",
    "  - hold out\n",
    "\n",
    "    - label :Uniform distribution better\n",
    "\n",
    "    - Randomly divide and average\n",
    "\n",
    "    - When the test set is small, the variance of the evaluation result is large\n",
    "\n",
    "    - When the training set is small, the evaluation result has a large deviation \n",
    "\n",
    "    - 2/3-4/5 for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec086ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('') #your dataset\n",
    "\n",
    "# Select target\n",
    "y = data.Price\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "melb_predictors = data.drop(['Price'], axis=1)\n",
    "X = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7147d7e0",
   "metadata": {},
   "source": [
    "  - cross vaidation\n",
    "\n",
    "    - k-fold cross vaidation\n",
    "\n",
    "      - k- 10\n",
    "\n",
    "      - k=1\n",
    "\n",
    "        - all data\n",
    "#### What is cross-validation?\n",
    "In cross-validation, we run our modeling process on different subsets of the data to get multiple measures of model quality.\n",
    "        <img src=\"cross_validation.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a20564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, random_state=0)   # your model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5, #dividing the data into 5 pieces\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d8b10",
   "metadata": {},
   "source": [
    "  - bootstrapping\n",
    "\n",
    "    - default\n",
    "\n",
    "      - Estimated Bias\n",
    "\n",
    "    - virtue\n",
    "\n",
    "      - small dataset\n",
    "\n",
    "      - Integrated learning\n",
    " \n",
    " //<a href=\"https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/\">算法详解</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c36c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Sample: [0.6, 0.4, 0.5, 0.1]\n",
      "OOB Sample: [0.2, 0.3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# data sample\n",
    "data = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "# prepare bootstrap sample\n",
    "boot = resample(data, replace=True, n_samples=4, random_state=1)\n",
    "print('Bootstrap Sample: %s' % boot)\n",
    "# out of bag observations\n",
    "oob = [x for x in data if x not in boot]\n",
    "print('OOB Sample: %s' % oob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eefbfe4",
   "metadata": {},
   "source": [
    "## <a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\">python model_selection API</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9144da",
   "metadata": {},
   "source": [
    "## Classification & Regression Evaluation Metrics\n",
    "<a href=\"https://www.kaggle.com/vipulgandhi/how-to-choose-right-metric-for-evaluating-ml-model\">a fantastic notebook for this</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61910f",
   "metadata": {},
   "source": [
    "### Classification Metrics \n",
    "accuracy, precision, recall, F1-score, ROC, AUC, …)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aeef4f",
   "metadata": {},
   "source": [
    "##### Classification Accuracy:\n",
    "number of correct predictions divided by the total number of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this API is nice!\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20c5ae",
   "metadata": {},
   "source": [
    "### Regression Metrics (MSE, MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324c317",
   "metadata": {},
   "source": [
    "-As a side note, it is also worth mentioning that metric is different from loss function. Loss functions are functions that show a measure of the model performance and are used to train a machine learning model (using some kind of optimization), and are usually differentiable in model’s parameters. On the other hand, metrics are used to monitor and measure the performance of a model (during training, and test), and do not need to be differentiable. However if for some tasks the performance metric is differentiable, it can be used both as a loss function (perhaps with some regularizations added to it), and a metric, such as MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009743aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
